{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Testing the LSTM sentiment-analysis model trained on the IMDB dataset\n",
    "### Author: Leonardo Esp√≠n\n",
    "#### Date: 4/25/2021\n",
    "\n",
    "* [Testing on the test data](#Testing-on-the-test-data)\n",
    "    * [Testing the model through the rest API](#Testing-the-model-through-the-rest-API)\n",
    "    * [Making a prediction through the rest API](#Making-a-prediction-through-the-rest-API)\n",
    "* [Testing on arbitrary text](#Testing-on-arbitrary-text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"../trainer\")\n",
    "# importing module in trainer folder\n",
    "import dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.load_model('/Users/leoespin/github/imdb-dataset/serve/1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 162,145\n",
      "Trainable params: 162,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the test data\n",
    "\n",
    "A value of **0 means a negative review, and 1 means a positive review**. The model returns the probability of the review being positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence:\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    1  591  202   14   31    6  717   10   10    2    2    5    4  360\n",
      "    7    4  177 5760  394  354    4  123    9 1035 1035 1035   10   10\n",
      "   13   92  124   89  488 7944  100   28 1668   14   31   23   27 7479\n",
      "   29  220  468    8  124   14  286  170    8  157   46    5   27  239\n",
      "   16  179    2   38   32   25 7944  451  202   14    6  717]\n",
      "corresponding label:\n",
      "0\n",
      "model prediction:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.07337198]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = dataprep.get_and_pad_imdb_dataset(maxlen=250) # default value used during training\n",
    "print('Input sequence:')\n",
    "print(x_test[0])\n",
    "print('corresponding label:')\n",
    "print(y_test[0])\n",
    "print('model prediction:')\n",
    "lstm_model.predict(x_test[None, 0, :]) # None is for adding extra dim to account for the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check input dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250,)\n",
      "(1, 250)\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0, :].shape)\n",
    "print(x_test[None, 0, :].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the `tensorflow/serving` container and load the model (after the service has started succesfully, stop the cell execution to be able to run other cells):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-26 20:08:15.082095: I tensorflow_serving/model_servers/server.cc:88] Building single TensorFlow model file config:  model_name: lstm_model model_base_path: /models/lstm_model\n",
      "2021-04-26 20:08:15.082538: I tensorflow_serving/model_servers/server_core.cc:464] Adding/updating models.\n",
      "2021-04-26 20:08:15.082626: I tensorflow_serving/model_servers/server_core.cc:587]  (Re-)adding model: lstm_model\n",
      "2021-04-26 20:08:15.191922: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: lstm_model version: 1}\n",
      "2021-04-26 20:08:15.191993: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: lstm_model version: 1}\n",
      "2021-04-26 20:08:15.192020: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: lstm_model version: 1}\n",
      "2021-04-26 20:08:15.193128: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /models/lstm_model/1\n",
      "2021-04-26 20:08:15.271145: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
      "2021-04-26 20:08:15.271210: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /models/lstm_model/1\n",
      "2021-04-26 20:08:15.272644: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-04-26 20:08:15.459014: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2021-04-26 20:08:15.483517: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1392000000 Hz\n",
      "2021-04-26 20:08:15.655116: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /models/lstm_model/1\n",
      "2021-04-26 20:08:15.773656: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 580545 microseconds.\n",
      "2021-04-26 20:08:15.789808: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/lstm_model/1/assets.extra/tf_serving_warmup_requests\n",
      "2021-04-26 20:08:15.807936: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: lstm_model version: 1}\n",
      "2021-04-26 20:08:15.811952: I tensorflow_serving/model_servers/server.cc:371] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n",
      "2021-04-26 20:08:15.813750: I tensorflow_serving/model_servers/server.cc:391] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 8501:8501 \\\n",
    "  --mount type=bind,source=/Users/leoespin/github/imdb-dataset/serve/,target=/models/lstm_model \\\n",
    "  -e MODEL_NAME=lstm_model -t tensorflow/serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model through the rest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_version_status\": [\n",
      "    {\n",
      "      \"state\": \"AVAILABLE\",\n",
      "      \"status\": {\n",
      "        \"error_code\": \"OK\",\n",
      "        \"error_message\": \"\"\n",
      "      },\n",
      "      \"version\": \"1\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Model status API\n",
    "model_name = 'lstm_model'\n",
    "x = requests.get(f'http://localhost:8501/v1/models/{model_name}')\n",
    "print(json.dumps(x.json(), indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metadata\": {\n",
      "    \"signature_def\": {\n",
      "      \"signature_def\": {\n",
      "        \"__saved_model_init_op\": {\n",
      "          \"inputs\": {},\n",
      "          \"method_name\": \"\",\n",
      "          \"outputs\": {\n",
      "            \"__saved_model_init_op\": {\n",
      "              \"dtype\": \"DT_INVALID\",\n",
      "              \"name\": \"NoOp\",\n",
      "              \"tensor_shape\": {\n",
      "                \"dim\": [],\n",
      "                \"unknown_rank\": true\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"serving_default\": {\n",
      "          \"inputs\": {\n",
      "            \"embedding_input\": {\n",
      "              \"dtype\": \"DT_FLOAT\",\n",
      "              \"name\": \"serving_default_embedding_input:0\",\n",
      "              \"tensor_shape\": {\n",
      "                \"dim\": [\n",
      "                  {\n",
      "                    \"name\": \"\",\n",
      "                    \"size\": \"-1\"\n",
      "                  },\n",
      "                  {\n",
      "                    \"name\": \"\",\n",
      "                    \"size\": \"-1\"\n",
      "                  }\n",
      "                ],\n",
      "                \"unknown_rank\": false\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"method_name\": \"tensorflow/serving/predict\",\n",
      "          \"outputs\": {\n",
      "            \"dense\": {\n",
      "              \"dtype\": \"DT_FLOAT\",\n",
      "              \"name\": \"StatefulPartitionedCall:0\",\n",
      "              \"tensor_shape\": {\n",
      "                \"dim\": [\n",
      "                  {\n",
      "                    \"name\": \"\",\n",
      "                    \"size\": \"-1\"\n",
      "                  },\n",
      "                  {\n",
      "                    \"name\": \"\",\n",
      "                    \"size\": \"1\"\n",
      "                  }\n",
      "                ],\n",
      "                \"unknown_rank\": false\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"model_spec\": {\n",
      "    \"name\": \"lstm_model\",\n",
      "    \"signature_name\": \"\",\n",
      "    \"version\": \"1\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Model Metadata API\n",
    "x = requests.get(f'http://localhost:8501/v1/models/{model_name}/metadata')\n",
    "print(json.dumps(x.json(), indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a prediction through the rest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\": \"application/json\"}\n",
    "data = json.dumps({\"instances\": x_test[None, 0, :].tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.0733719766\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_response = requests.post('http://localhost:8501/v1/models/lstm_model:predict',\n",
    "                              data = data, headers = headers)\n",
    "print(json.dumps(json_response.json(), indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on arbitrary text\n",
    "\n",
    "* preprocess and tokenize sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word index for the IMDB dataset\n",
    "imdb_word_index = dataprep.get_imdb_word_index()\n",
    "\n",
    "good = dataprep.clean_tokenize('I like it, very nice!', imdb_word_index)\n",
    "bad = dataprep.clean_tokenize('worst movie ever', imdb_word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    [\n",
      "      0.778687477\n",
      "    ],\n",
      "    [\n",
      "      0.0709086359\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data = json.dumps({\"instances\" : [ good[0], bad[0] ]})\n",
    "json_response = requests.post('http://localhost:8501/v1/models/lstm_model:predict',\n",
    "                              data = data, headers = headers)\n",
    "print(json.dumps(json_response.json(), indent=2, sort_keys=True))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "imdb",
   "language": "python",
   "name": "imdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}